# Important Concept and Theory about DL

## Saturate neuron(Dying ReLU)
 - [What is the benefit of the truncated normal distribution in initializing weights in a neural network](https://stats.stackexchange.com/questions/228670/what-is-the-benefit-of-the-truncated-normal-distribution-in-initializing-weights)
 - [What is difference between tf.truncated_normal and tf.random_normal](https://stackoverflow.com/questions/41704484/what-is-difference-between-tf-truncated-normal-and-tf-random-normal)
 - [What is the definition of a dead neuron in Artificial Neural Networks](https://www.quora.com/What-is-the-definition-of-a-dead-neuron-in-Artificial-Neural-Networks)
 - [What is the difference between dead neuron and killing the gradient](https://stats.stackexchange.com/questions/230399/what-is-the-difference-between-dead-neuron-and-killing-the-gradient)
 - [What is the “dying ReLU” problem in neural networks](https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks)
 - [What is the "dying ReLU" problem in neural networks](https://www.quora.com/What-is-the-dying-ReLU-problem-in-neural-networks)

